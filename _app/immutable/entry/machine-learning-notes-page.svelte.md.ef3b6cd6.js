import{S as Kl,i as Wl,s as zl,U as Wa,y as Vl,z as Zl,A as jl,V as Ql,W as Pl,g as Yl,d as sn,B as en,X as Hl,k as l,q as t,a as F,Y as Ja,e as Ol,l as n,m as o,r,h as a,c,Z as Ka,n as f,b as p,D as e,E as an}from"../chunks/index.85533aa3.js";import{P as ln}from"../chunks/post_layout.81fb120e.js";function nn(H){let d,u,b,L,y,m,O,Js,S,B,ye,Ks,v,ds,De,fe,$,ue,h,ys,me,Ee,Ds,he,ve,fs,ge,Ae,us,_e,be,ms,we,Ws,N,q,Le,zs,J,Te,Vs,T,K,Es,Ce,Ie,xe,g,hs,Re,Me,Se,Ne,ke,Ge,Zs,W,Ue,js,A,z,vs,Xe,Pe,He,V,gs,Oe,Be,$e,Z,As,qe,Je,Qs,k,j,Ke,Ys,E,Q,_s,We,ze,Ve,Y,bs,Ze,je,Qe,ss,ws,Ye,sa,ea,es,Ls,aa,la,se,G,as,na,ee,C,ls,Ts,oa,ta,ra,ns,Cs,ia,pa,ae,U,os,Fa,le,I,ca,Is,da,ya,ne,ts,Da,oe,x,xs,fa,ua,Rs,ma,te,X,rs,Ea,re,D,Ms,ha,va,Ss,ga,Aa,Ns,_a,ba,is,wa,w,ks,La,Ta,Gs,Ca,Ia,Us,xa,Ra,Xs,Ma,ie,Ps,$l=`<pre class="shiki material-default" style="background-color: #263238; color: #EEFFFF" python="true"><div class="language-id">python</div><div class='code-container'><code><div class='line'><span style="color: #546E7A"># This is code implementation of Cost function.</span></div><div class='line'><span style="color: #89DDFF">import</span><span style="color: #EEFFFF"> numpy </span><span style="color: #89DDFF">as</span><span style="color: #EEFFFF"> np</span></div><div class='line'><span style="color: #C792EA">def</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">compute_cost</span><span style="color: #89DDFF">(</span><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">y</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">theta</span><span style="color: #89DDFF">):</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #546E7A">  Calculates the cost function for given data</span></div><div class='line'></div><div class='line'><span style="color: #546E7A">  Arguments:</span></div><div class='line'><span style="color: #546E7A">  X : Input features passed in as vector or matrix(if multiple features)(use numpy)</span></div><div class='line'><span style="color: #546E7A">  y : Labels or ground truth values passed in as a vector</span></div><div class='line'><span style="color: #546E7A">  theta : parameters matrix for calculating the hypothesis function h.(should be passed as an array)</span></div><div class='line'><span style="color: #546E7A">  </span></div><div class='line'><span style="color: #546E7A">  Returns:</span></div><div class='line'><span style="color: #546E7A">  The cost function for all the training examples in dataset</span></div><div class='line'></div><div class='line'><span style="color: #546E7A">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #EEFFFF">  m </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">len</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  X </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">array</span><span style="color: #89DDFF">([</span><span style="color: #82AAFF">np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">ones</span><span style="color: #89DDFF">((</span><span style="color: #82AAFF">m</span><span style="color: #89DDFF">)),</span><span style="color: #82AAFF"> X</span><span style="color: #89DDFF">])</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #82AAFF">print</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  h </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> theta</span><span style="color: #89DDFF">.</span><span style="color: #F07178">T</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">*</span><span style="color: #EEFFFF"> X </span><span style="color: #546E7A"># matrix multiplication</span></div><div class='line'><span style="color: #EEFFFF">  C</span><span style="color: #89DDFF">=[]</span></div><div class='line'><span style="color: #EEFFFF">  C</span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF">h</span><span style="color: #89DDFF">-</span><span style="color: #EEFFFF">y</span></div><div class='line'><span style="color: #EEFFFF">  C</span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF">np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">square</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">C</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  J</span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF">np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">sum</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">C</span><span style="color: #89DDFF">)/(</span><span style="color: #F78C6C">2</span><span style="color: #89DDFF">*</span><span style="color: #EEFFFF">m</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">return</span><span style="color: #EEFFFF"> J</span></div></code></div></pre>`,Hs,Os,ql=`<pre class="shiki material-default" style="background-color: #263238; color: #EEFFFF" python="true"><div class="language-id">python</div><div class='code-container'><code><div class='line'><span style="color: #546E7A"># Implementation of Gradient Descent Algorithm</span></div><div class='line'><span style="color: #C792EA">def</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">gradient_descent</span><span style="color: #89DDFF">(</span><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">y</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">theta</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">alpha</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> num_iters</span><span style="color: #89DDFF">):</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #546E7A">  Performs the gradient descent for the Data given no of iterations</span></div><div class='line'></div><div class='line'><span style="color: #546E7A">  Arguments:</span></div><div class='line'><span style="color: #546E7A">  X: Input array of data (for uni-variate linear reg : dim = (m,2))</span></div><div class='line'><span style="color: #546E7A">  y: labels</span></div><div class='line'><span style="color: #546E7A">  theta: parameters matrix (for 2 parameters : dim = (2,1))</span></div><div class='line'><span style="color: #546E7A">  Note: Dimensions of H : (m,1), Dimensions of y : (m,1) (Both should be equal)</span></div><div class='line'><span style="color: #546E7A">  Returns:</span></div><div class='line'><span style="color: #546E7A">  Theta values after the minimization process of loss function</span></div><div class='line'><span style="color: #546E7A">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #EEFFFF">  J_history </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">zeros</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">num_iters</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  m </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">len</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">for</span><span style="color: #EEFFFF"> iters </span><span style="color: #89DDFF">in</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">range</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">num_iters</span><span style="color: #89DDFF">-</span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">):</span></div><div class='line'><span style="color: #EEFFFF">    H </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">matmul</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF">theta</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    J </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">square</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">H</span><span style="color: #89DDFF">-</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    K </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">(</span><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">.</span><span style="color: #F07178">T</span><span style="color: #89DDFF">)</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">*</span><span style="color: #EEFFFF"> J</span></div><div class='line'><span style="color: #EEFFFF">    K </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> K</span><span style="color: #89DDFF">/</span><span style="color: #EEFFFF">m</span></div><div class='line'><span style="color: #EEFFFF">    </span><span style="color: #546E7A"># Theta update step(parameter update step)</span></div><div class='line'></div><div class='line'><span style="color: #EEFFFF">    theta </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> theta </span><span style="color: #89DDFF">-</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">((</span><span style="color: #EEFFFF">alpha</span><span style="color: #89DDFF">)*</span><span style="color: #EEFFFF">K</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    J_history</span><span style="color: #89DDFF">[</span><span style="color: #EEFFFF">iters</span><span style="color: #89DDFF">]</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">compute_cost</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> y</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> theta</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    </span><span style="color: #89DDFF">return</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">[</span><span style="color: #EEFFFF">theta</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> J_history</span><span style="color: #89DDFF">]</span></div><div class='line'></div><div class='line'></div></code></div></pre>`,Bs,$s,Jl=`<pre class="shiki material-default" style="background-color: #263238; color: #EEFFFF" python="true"><div class="language-id">python</div><div class='code-container'><code><div class='line'><span style="color: #546E7A"># An example code snippet illustrating the linear regression </span></div><div class='line'><span style="color: #546E7A"># Loading the dataset and preparing the data for the model training</span></div><div class='line'><span style="color: #89DDFF">import</span><span style="color: #EEFFFF"> pandas </span><span style="color: #89DDFF">as</span><span style="color: #EEFFFF"> pd</span></div><div class='line'><span style="color: #EEFFFF">df </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> pd</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">read_csv</span><span style="color: #89DDFF">(</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">/content/linear_reg.csv</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">names</span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">[</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">X</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">,</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">y</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">])</span></div><div class='line'><span style="color: #EEFFFF">X </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> df</span><span style="color: #89DDFF">[</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">X</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">].</span><span style="color: #82AAFF">to_numpy</span><span style="color: #89DDFF">()</span></div><div class='line'><span style="color: #EEFFFF">y </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> df</span><span style="color: #89DDFF">[</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">y</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">].</span><span style="color: #82AAFF">to_numpy</span><span style="color: #89DDFF">()</span></div><div class='line'><span style="color: #EEFFFF">theta  </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">array</span><span style="color: #89DDFF">([</span><span style="color: #F78C6C">1</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">2</span><span style="color: #89DDFF">])</span></div><div class='line'><span style="color: #EEFFFF">X </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">expand_dims</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">axis</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">y </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">expand_dims</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">axis</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">theta </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">expand_dims</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">theta</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">axis</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> y</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> theta</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span></div></code></div></pre>`,qs;return{c(){d=l("h1"),u=l("a"),b=t("Machine Learning Course Notes - AndrewNg(with code implementations of Algorithms)"),L=F(),y=l("blockquote"),m=l("p"),O=t("My entire Machine learning course notes along with code implementations for all algorithms. The notes are based on the course taught by AndrewNg offered by stanford on Coursera."),Js=F(),S=l("h2"),B=l("a"),ye=t("Introduction to Machine learning:"),Ks=F(),v=l("ul"),ds=l("li"),De=t("Types of ML problems"),fe=F(),$=l("li"),ue=t("Types of ML algorithms:"),h=l("ul"),ys=l("li"),me=t("Supervised learning"),Ee=F(),Ds=l("li"),he=t("Unsupervised learning"),ve=F(),fs=l("li"),ge=t("semi supervised learning"),Ae=F(),us=l("li"),_e=t("Reinforcement learning"),be=F(),ms=l("li"),we=t("Singular Value Decomposition method"),Ws=F(),N=l("h3"),q=l("a"),Le=t("Definition of Machine Learning:"),zs=F(),J=l("p"),Te=t("Many attempts were made to define what is machine learning. Some of the prominent definitions are:"),Vs=F(),T=l("ul"),K=l("li"),Es=l("strong"),Ce=t("Arthur Samuel(1959)"),Ie=t(" : Field of study that gives computers the ability to learn without being explicitly programmed."),xe=F(),g=l("li"),hs=l("strong"),Re=t("Tom Mitchell(1998)"),Me=t(":"),Se=l("br"),Ne=t(`
A well-posed learning problem is defined as:`),ke=l("br"),Ge=t(`
A computer program is said to learn from experience “E” with respect to some task “T” and some performance measure “P”, if its performance on T as measured by P improves with E.`),Zs=F(),W=l("p"),Ue=t("Ex:  An email program detecting spam mails. In this example:"),js=F(),A=l("ul"),z=l("li"),vs=l("strong"),Xe=t("Task “T”:"),Pe=t(" classifying emails as spam or not"),He=F(),V=l("li"),gs=l("strong"),Oe=t("Experience “E”:"),Be=t(" watching you label email as spam or not spam"),$e=F(),Z=l("li"),As=l("strong"),qe=t("Performance “P”:"),Je=t(" Fraction of emails correctly classified."),Qs=F(),k=l("h3"),j=l("a"),Ke=t("Types of ML Algorithms(based on learning methods):"),Ys=F(),E=l("ul"),Q=l("li"),_s=l("strong"),We=t("Supervised Learning:"),ze=t(" We give the dataset which contains input data with the labelled ground truths so that the model can learn from it and when trained can produce results which are more close to the actual labels."),Ve=F(),Y=l("li"),bs=l("strong"),Ze=t("Unsupervised Learning:"),je=t("   Allows us to approach problems with little or no idea what our results would look like. These learning algorithms are used to identify the patterns in dataset that has datapoints that are neither classified nor labelled."),Qe=F(),ss=l("li"),ws=l("strong"),Ye=t("Semi-supervised learning:"),sa=t("  is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). It is a special instance of weak supervision."),ea=F(),es=l("li"),Ls=l("strong"),aa=t("Reinforcement learning:"),la=t(" Reinforcement learning is a machine learning training method based on rewarding desired behaviors and/or punishing undesired ones. In general, a reinforcement learning agent is able to perceive and interpret its environment, take actions and learn through trial and error."),se=F(),G=l("h3"),as=l("a"),na=t("Types of problems in supervised learning:"),ee=F(),C=l("ul"),ls=l("li"),Ts=l("strong"),oa=t("Regression problems:"),ta=t(" These are problems where our predictions have continous value attribute.(for example: Housing price prediction given different factors as input in the dataset, here house prices are continuous value numbers)"),ra=F(),ns=l("li"),Cs=l("strong"),ia=t("Classification problems"),pa=t(": These problems have predictions that are discrete valued (for example: output is there 0(or)1 for binary classification)"),ae=F(),U=l("h3"),os=l("a"),Fa=t("Types of problems in Unsupervised learning:"),le=F(),I=l("p"),ca=t("Given, a dataset the unsupervised learning algorithms will try to find some structure of pattern in the data. It decides that data lives in separate clusters. An example of this is "),Is=l("strong"),da=t("“Clustering Algorithm”"),ya=t("."),ne=F(),ts=l("p"),Da=t("Examples:"),oe=F(),x=l("ul"),xs=l("li"),fa=t("Like Newstories in google news are arranged in a cohesive way"),ua=F(),Rs=l("li"),ma=t("Genome identification and clustering the people based on genome."),te=F(),X=l("h2"),rs=l("a"),Ea=t("Regression problems (Linear Regression):"),re=F(),D=l("ul"),Ms=l("li"),ha=t("Weights and Bias units"),va=F(),Ss=l("li"),ga=t("Contour plots"),Aa=F(),Ns=l("li"),_a=t("Key Idea"),ba=F(),is=l("li"),wa=t("Gradient Descent Algorithm"),w=l("ul"),ks=l("li"),La=t("For linear regression"),Ta=F(),Gs=l("li"),Ca=t("Batch Gradient Descent"),Ia=F(),Us=l("li"),xa=t("Gradient Descent for Multi variable regression"),Ra=F(),Xs=l("li"),Ma=t("Cost Function and Loss function"),ie=F(),Ps=new Ja(!1),Hs=F(),Os=new Ja(!1),Bs=F(),$s=new Ja(!1),qs=Ol(),this.h()},l(s){d=n(s,"H1",{id:!0});var i=o(d);u=n(i,"A",{href:!0});var za=o(u);b=r(za,"Machine Learning Course Notes - AndrewNg(with code implementations of Algorithms)"),za.forEach(a),i.forEach(a),L=c(s),y=n(s,"BLOCKQUOTE",{});var Va=o(y);m=n(Va,"P",{});var Za=o(m);O=r(Za,"My entire Machine learning course notes along with code implementations for all algorithms. The notes are based on the course taught by AndrewNg offered by stanford on Coursera."),Za.forEach(a),Va.forEach(a),Js=c(s),S=n(s,"H2",{id:!0});var ja=o(S);B=n(ja,"A",{href:!0});var Qa=o(B);ye=r(Qa,"Introduction to Machine learning:"),Qa.forEach(a),ja.forEach(a),Ks=c(s),v=n(s,"UL",{});var ps=o(v);ds=n(ps,"LI",{});var Ya=o(ds);De=r(Ya,"Types of ML problems"),Ya.forEach(a),fe=c(ps),$=n(ps,"LI",{});var Sa=o($);ue=r(Sa,"Types of ML algorithms:"),h=n(Sa,"UL",{});var R=o(h);ys=n(R,"LI",{});var sl=o(ys);me=r(sl,"Supervised learning"),sl.forEach(a),Ee=c(R),Ds=n(R,"LI",{});var el=o(Ds);he=r(el,"Unsupervised learning"),el.forEach(a),ve=c(R),fs=n(R,"LI",{});var al=o(fs);ge=r(al,"semi supervised learning"),al.forEach(a),Ae=c(R),us=n(R,"LI",{});var ll=o(us);_e=r(ll,"Reinforcement learning"),ll.forEach(a),R.forEach(a),Sa.forEach(a),be=c(ps),ms=n(ps,"LI",{});var nl=o(ms);we=r(nl,"Singular Value Decomposition method"),nl.forEach(a),ps.forEach(a),Ws=c(s),N=n(s,"H3",{id:!0});var ol=o(N);q=n(ol,"A",{href:!0});var tl=o(q);Le=r(tl,"Definition of Machine Learning:"),tl.forEach(a),ol.forEach(a),zs=c(s),J=n(s,"P",{});var rl=o(J);Te=r(rl,"Many attempts were made to define what is machine learning. Some of the prominent definitions are:"),rl.forEach(a),Vs=c(s),T=n(s,"UL",{});var pe=o(T);K=n(pe,"LI",{});var Na=o(K);Es=n(Na,"STRONG",{});var il=o(Es);Ce=r(il,"Arthur Samuel(1959)"),il.forEach(a),Ie=r(Na," : Field of study that gives computers the ability to learn without being explicitly programmed."),Na.forEach(a),xe=c(pe),g=n(pe,"LI",{});var P=o(g);hs=n(P,"STRONG",{});var pl=o(hs);Re=r(pl,"Tom Mitchell(1998)"),pl.forEach(a),Me=r(P,":"),Se=n(P,"BR",{}),Ne=r(P,`
A well-posed learning problem is defined as:`),ke=n(P,"BR",{}),Ge=r(P,`
A computer program is said to learn from experience “E” with respect to some task “T” and some performance measure “P”, if its performance on T as measured by P improves with E.`),P.forEach(a),pe.forEach(a),Zs=c(s),W=n(s,"P",{});var Fl=o(W);Ue=r(Fl,"Ex:  An email program detecting spam mails. In this example:"),Fl.forEach(a),js=c(s),A=n(s,"UL",{});var Fs=o(A);z=n(Fs,"LI",{});var ka=o(z);vs=n(ka,"STRONG",{});var cl=o(vs);Xe=r(cl,"Task “T”:"),cl.forEach(a),Pe=r(ka," classifying emails as spam or not"),ka.forEach(a),He=c(Fs),V=n(Fs,"LI",{});var Ga=o(V);gs=n(Ga,"STRONG",{});var dl=o(gs);Oe=r(dl,"Experience “E”:"),dl.forEach(a),Be=r(Ga," watching you label email as spam or not spam"),Ga.forEach(a),$e=c(Fs),Z=n(Fs,"LI",{});var Ua=o(Z);As=n(Ua,"STRONG",{});var yl=o(As);qe=r(yl,"Performance “P”:"),yl.forEach(a),Je=r(Ua," Fraction of emails correctly classified."),Ua.forEach(a),Fs.forEach(a),Qs=c(s),k=n(s,"H3",{id:!0});var Dl=o(k);j=n(Dl,"A",{href:!0});var fl=o(j);Ke=r(fl,"Types of ML Algorithms(based on learning methods):"),fl.forEach(a),Dl.forEach(a),Ys=c(s),E=n(s,"UL",{});var M=o(E);Q=n(M,"LI",{});var Xa=o(Q);_s=n(Xa,"STRONG",{});var ul=o(_s);We=r(ul,"Supervised Learning:"),ul.forEach(a),ze=r(Xa," We give the dataset which contains input data with the labelled ground truths so that the model can learn from it and when trained can produce results which are more close to the actual labels."),Xa.forEach(a),Ve=c(M),Y=n(M,"LI",{});var Pa=o(Y);bs=n(Pa,"STRONG",{});var ml=o(bs);Ze=r(ml,"Unsupervised Learning:"),ml.forEach(a),je=r(Pa,"   Allows us to approach problems with little or no idea what our results would look like. These learning algorithms are used to identify the patterns in dataset that has datapoints that are neither classified nor labelled."),Pa.forEach(a),Qe=c(M),ss=n(M,"LI",{});var Ha=o(ss);ws=n(Ha,"STRONG",{});var El=o(ws);Ye=r(El,"Semi-supervised learning:"),El.forEach(a),sa=r(Ha,"  is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). It is a special instance of weak supervision."),Ha.forEach(a),ea=c(M),es=n(M,"LI",{});var Oa=o(es);Ls=n(Oa,"STRONG",{});var hl=o(Ls);aa=r(hl,"Reinforcement learning:"),hl.forEach(a),la=r(Oa," Reinforcement learning is a machine learning training method based on rewarding desired behaviors and/or punishing undesired ones. In general, a reinforcement learning agent is able to perceive and interpret its environment, take actions and learn through trial and error."),Oa.forEach(a),M.forEach(a),se=c(s),G=n(s,"H3",{id:!0});var vl=o(G);as=n(vl,"A",{href:!0});var gl=o(as);na=r(gl,"Types of problems in supervised learning:"),gl.forEach(a),vl.forEach(a),ee=c(s),C=n(s,"UL",{});var Fe=o(C);ls=n(Fe,"LI",{});var Ba=o(ls);Ts=n(Ba,"STRONG",{});var Al=o(Ts);oa=r(Al,"Regression problems:"),Al.forEach(a),ta=r(Ba," These are problems where our predictions have continous value attribute.(for example: Housing price prediction given different factors as input in the dataset, here house prices are continuous value numbers)"),Ba.forEach(a),ra=c(Fe),ns=n(Fe,"LI",{});var $a=o(ns);Cs=n($a,"STRONG",{});var _l=o(Cs);ia=r(_l,"Classification problems"),_l.forEach(a),pa=r($a,": These problems have predictions that are discrete valued (for example: output is there 0(or)1 for binary classification)"),$a.forEach(a),Fe.forEach(a),ae=c(s),U=n(s,"H3",{id:!0});var bl=o(U);os=n(bl,"A",{href:!0});var wl=o(os);Fa=r(wl,"Types of problems in Unsupervised learning:"),wl.forEach(a),bl.forEach(a),le=c(s),I=n(s,"P",{});var ce=o(I);ca=r(ce,"Given, a dataset the unsupervised learning algorithms will try to find some structure of pattern in the data. It decides that data lives in separate clusters. An example of this is "),Is=n(ce,"STRONG",{});var Ll=o(Is);da=r(Ll,"“Clustering Algorithm”"),Ll.forEach(a),ya=r(ce,"."),ce.forEach(a),ne=c(s),ts=n(s,"P",{});var Tl=o(ts);Da=r(Tl,"Examples:"),Tl.forEach(a),oe=c(s),x=n(s,"UL",{});var de=o(x);xs=n(de,"LI",{});var Cl=o(xs);fa=r(Cl,"Like Newstories in google news are arranged in a cohesive way"),Cl.forEach(a),ua=c(de),Rs=n(de,"LI",{});var Il=o(Rs);ma=r(Il,"Genome identification and clustering the people based on genome."),Il.forEach(a),de.forEach(a),te=c(s),X=n(s,"H2",{id:!0});var xl=o(X);rs=n(xl,"A",{href:!0});var Rl=o(rs);Ea=r(Rl,"Regression problems (Linear Regression):"),Rl.forEach(a),xl.forEach(a),re=c(s),D=n(s,"UL",{});var _=o(D);Ms=n(_,"LI",{});var Ml=o(Ms);ha=r(Ml,"Weights and Bias units"),Ml.forEach(a),va=c(_),Ss=n(_,"LI",{});var Sl=o(Ss);ga=r(Sl,"Contour plots"),Sl.forEach(a),Aa=c(_),Ns=n(_,"LI",{});var Nl=o(Ns);_a=r(Nl,"Key Idea"),Nl.forEach(a),ba=c(_),is=n(_,"LI",{});var qa=o(is);wa=r(qa,"Gradient Descent Algorithm"),w=n(qa,"UL",{});var cs=o(w);ks=n(cs,"LI",{});var kl=o(ks);La=r(kl,"For linear regression"),kl.forEach(a),Ta=c(cs),Gs=n(cs,"LI",{});var Gl=o(Gs);Ca=r(Gl,"Batch Gradient Descent"),Gl.forEach(a),Ia=c(cs),Us=n(cs,"LI",{});var Ul=o(Us);xa=r(Ul,"Gradient Descent for Multi variable regression"),Ul.forEach(a),cs.forEach(a),qa.forEach(a),Ra=c(_),Xs=n(_,"LI",{});var Xl=o(Xs);Ma=r(Xl,"Cost Function and Loss function"),Xl.forEach(a),_.forEach(a),ie=c(s),Ps=Ka(s,!1),Hs=c(s),Os=Ka(s,!1),Bs=c(s),$s=Ka(s,!1),qs=Ol(),this.h()},h(){f(u,"href","#machine-learning-course-notes---andrewngwith-code-implementations-of-algorithms"),f(d,"id","machine-learning-course-notes---andrewngwith-code-implementations-of-algorithms"),f(B,"href","#introduction-to-machine-learning"),f(S,"id","introduction-to-machine-learning"),f(q,"href","#definition-of-machine-learning"),f(N,"id","definition-of-machine-learning"),f(j,"href","#types-of-ml-algorithmsbased-on-learning-methods"),f(k,"id","types-of-ml-algorithmsbased-on-learning-methods"),f(as,"href","#types-of-problems-in-supervised-learning"),f(G,"id","types-of-problems-in-supervised-learning"),f(os,"href","#types-of-problems-in-unsupervised-learning"),f(U,"id","types-of-problems-in-unsupervised-learning"),f(rs,"href","#regression-problems-linear-regression"),f(X,"id","regression-problems-linear-regression"),Ps.a=Hs,Os.a=Bs,$s.a=qs},m(s,i){p(s,d,i),e(d,u),e(u,b),p(s,L,i),p(s,y,i),e(y,m),e(m,O),p(s,Js,i),p(s,S,i),e(S,B),e(B,ye),p(s,Ks,i),p(s,v,i),e(v,ds),e(ds,De),e(v,fe),e(v,$),e($,ue),e($,h),e(h,ys),e(ys,me),e(h,Ee),e(h,Ds),e(Ds,he),e(h,ve),e(h,fs),e(fs,ge),e(h,Ae),e(h,us),e(us,_e),e(v,be),e(v,ms),e(ms,we),p(s,Ws,i),p(s,N,i),e(N,q),e(q,Le),p(s,zs,i),p(s,J,i),e(J,Te),p(s,Vs,i),p(s,T,i),e(T,K),e(K,Es),e(Es,Ce),e(K,Ie),e(T,xe),e(T,g),e(g,hs),e(hs,Re),e(g,Me),e(g,Se),e(g,Ne),e(g,ke),e(g,Ge),p(s,Zs,i),p(s,W,i),e(W,Ue),p(s,js,i),p(s,A,i),e(A,z),e(z,vs),e(vs,Xe),e(z,Pe),e(A,He),e(A,V),e(V,gs),e(gs,Oe),e(V,Be),e(A,$e),e(A,Z),e(Z,As),e(As,qe),e(Z,Je),p(s,Qs,i),p(s,k,i),e(k,j),e(j,Ke),p(s,Ys,i),p(s,E,i),e(E,Q),e(Q,_s),e(_s,We),e(Q,ze),e(E,Ve),e(E,Y),e(Y,bs),e(bs,Ze),e(Y,je),e(E,Qe),e(E,ss),e(ss,ws),e(ws,Ye),e(ss,sa),e(E,ea),e(E,es),e(es,Ls),e(Ls,aa),e(es,la),p(s,se,i),p(s,G,i),e(G,as),e(as,na),p(s,ee,i),p(s,C,i),e(C,ls),e(ls,Ts),e(Ts,oa),e(ls,ta),e(C,ra),e(C,ns),e(ns,Cs),e(Cs,ia),e(ns,pa),p(s,ae,i),p(s,U,i),e(U,os),e(os,Fa),p(s,le,i),p(s,I,i),e(I,ca),e(I,Is),e(Is,da),e(I,ya),p(s,ne,i),p(s,ts,i),e(ts,Da),p(s,oe,i),p(s,x,i),e(x,xs),e(xs,fa),e(x,ua),e(x,Rs),e(Rs,ma),p(s,te,i),p(s,X,i),e(X,rs),e(rs,Ea),p(s,re,i),p(s,D,i),e(D,Ms),e(Ms,ha),e(D,va),e(D,Ss),e(Ss,ga),e(D,Aa),e(D,Ns),e(Ns,_a),e(D,ba),e(D,is),e(is,wa),e(is,w),e(w,ks),e(ks,La),e(w,Ta),e(w,Gs),e(Gs,Ca),e(w,Ia),e(w,Us),e(Us,xa),e(D,Ra),e(D,Xs),e(Xs,Ma),p(s,ie,i),Ps.m($l,s,i),p(s,Hs,i),Os.m(ql,s,i),p(s,Bs,i),$s.m(Jl,s,i),p(s,qs,i)},p:an,d(s){s&&a(d),s&&a(L),s&&a(y),s&&a(Js),s&&a(S),s&&a(Ks),s&&a(v),s&&a(Ws),s&&a(N),s&&a(zs),s&&a(J),s&&a(Vs),s&&a(T),s&&a(Zs),s&&a(W),s&&a(js),s&&a(A),s&&a(Qs),s&&a(k),s&&a(Ys),s&&a(E),s&&a(se),s&&a(G),s&&a(ee),s&&a(C),s&&a(ae),s&&a(U),s&&a(le),s&&a(I),s&&a(ne),s&&a(ts),s&&a(oe),s&&a(x),s&&a(te),s&&a(X),s&&a(re),s&&a(D),s&&a(ie),s&&Ps.d(),s&&a(Hs),s&&Os.d(),s&&a(Bs),s&&a(qs),s&&$s.d()}}}function on(H){let d,u;const b=[H[0],Bl];let L={$$slots:{default:[nn]},$$scope:{ctx:H}};for(let y=0;y<b.length;y+=1)L=Wa(L,b[y]);return d=new ln({props:L}),{c(){Vl(d.$$.fragment)},l(y){Zl(d.$$.fragment,y)},m(y,m){jl(d,y,m),u=!0},p(y,[m]){const O=m&1?Ql(b,[m&1&&Pl(y[0]),m&0&&Pl(Bl)]):{};m&2&&(O.$$scope={dirty:m,ctx:y}),d.$set(O)},i(y){u||(Yl(d.$$.fragment,y),u=!0)},o(y){sn(d.$$.fragment,y),u=!1},d(y){en(d,y)}}}const Bl={title:"Machine Learning Course Notes(Andrew Ng Course)",summary:"Course Notes of Andrew Ng's Machine Learning course on Coursera",created:"2021-11-01T00:00:00.000Z",tags:["Machine Learning"],toc:[{depth:1,title:"Machine Learning Course Notes - AndrewNg(with code implementations of Algorithms)",slug:"machine-learning-course-notes---andrewngwith-code-implementations-of-algorithms"},{depth:2,title:"Introduction to Machine learning:",slug:"introduction-to-machine-learning"},{depth:3,title:"Definition of Machine Learning:",slug:"definition-of-machine-learning"},{depth:3,title:"Types of ML Algorithms(based on learning methods):",slug:"types-of-ml-algorithmsbased-on-learning-methods"},{depth:3,title:"Types of problems in supervised learning:",slug:"types-of-problems-in-supervised-learning"},{depth:3,title:"Types of problems in Unsupervised learning:",slug:"types-of-problems-in-unsupervised-learning"},{depth:2,title:"Regression problems (Linear Regression):",slug:"regression-problems-linear-regression"}],flags:[],updated:"2023-05-21T10:50:44.336Z",slug:"/machine-learning-notes/+page.svelte.md",path:"/machine-learning-notes"};function tn(H,d,u){return H.$$set=b=>{u(0,d=Wa(Wa({},d),Hl(b)))},d=Hl(d),[d]}class Fn extends Kl{constructor(d){super(),Wl(this,d,tn,on,zl,{})}}export{Fn as default,Bl as metadata};
