import{S as Ka,i as Wa,s as Za,U as Wl,y as za,z as Va,A as ja,V as Qa,W as Pa,g as Ya,d as sn,B as en,X as Ha,k as a,q as t,a as F,Y as Jl,e as Oa,l as n,m as o,r,h as l,c,Z as Kl,n as f,b as p,D as e,E as ln}from"../chunks/index.85533aa3.js";import{P as an}from"../chunks/post_layout.81fb120e.js";function nn(H){let d,u,b,L,y,m,O,Js,S,B,ye,Ks,v,ds,De,fe,$,ue,h,ys,me,Ee,Ds,he,ve,fs,ge,Ae,us,_e,be,ms,we,Ws,N,q,Le,Zs,J,Te,zs,T,K,Es,Ce,Ie,xe,g,hs,Re,Me,Se,Ne,ke,Ge,Vs,W,Ue,js,A,Z,vs,Xe,Pe,He,z,gs,Oe,Be,$e,V,As,qe,Je,Qs,k,j,Ke,Ys,E,Q,_s,We,Ze,ze,Y,bs,Ve,je,Qe,ss,ws,Ye,sl,el,es,Ls,ll,al,se,G,ls,nl,ee,C,as,Ts,ol,tl,rl,ns,Cs,il,pl,le,U,os,Fl,ae,I,cl,Is,dl,yl,ne,ts,Dl,oe,x,xs,fl,ul,Rs,ml,te,X,rs,El,re,D,Ms,hl,vl,Ss,gl,Al,Ns,_l,bl,is,wl,w,ks,Ll,Tl,Gs,Cl,Il,Us,xl,Rl,Xs,Ml,ie,Ps,$a=`<pre class="shiki material-default" style="background-color: #263238; color: #EEFFFF" python="true"><div class="language-id">python</div><div class='code-container'><code><div class='line'><span style="color: #546E7A"># This is code implementation of Cost function.</span></div><div class='line'><span style="color: #89DDFF">import</span><span style="color: #EEFFFF"> numpy </span><span style="color: #89DDFF">as</span><span style="color: #EEFFFF"> np</span></div><div class='line'><span style="color: #C792EA">def</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">compute_cost</span><span style="color: #89DDFF">(</span><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">y</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">theta</span><span style="color: #89DDFF">):</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #546E7A">  Calculates the cost function for given data</span></div><div class='line'></div><div class='line'><span style="color: #546E7A">  Arguments:</span></div><div class='line'><span style="color: #546E7A">  X : Input features passed in as vector or matrix(if multiple features)(use numpy)</span></div><div class='line'><span style="color: #546E7A">  y : Labels or ground truth values passed in as a vector</span></div><div class='line'><span style="color: #546E7A">  theta : parameters matrix for calculating the hypothesis function h.(should be passed as an array)</span></div><div class='line'><span style="color: #546E7A">  </span></div><div class='line'><span style="color: #546E7A">  Returns:</span></div><div class='line'><span style="color: #546E7A">  The cost function for all the training examples in dataset</span></div><div class='line'></div><div class='line'><span style="color: #546E7A">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #EEFFFF">  m </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">len</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  X </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">array</span><span style="color: #89DDFF">([</span><span style="color: #82AAFF">np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">ones</span><span style="color: #89DDFF">((</span><span style="color: #82AAFF">m</span><span style="color: #89DDFF">)),</span><span style="color: #82AAFF"> X</span><span style="color: #89DDFF">])</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #82AAFF">print</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  h </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> theta</span><span style="color: #89DDFF">.</span><span style="color: #F07178">T</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">*</span><span style="color: #EEFFFF"> X </span><span style="color: #546E7A"># matrix multiplication</span></div><div class='line'><span style="color: #EEFFFF">  C</span><span style="color: #89DDFF">=[]</span></div><div class='line'><span style="color: #EEFFFF">  C</span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF">h</span><span style="color: #89DDFF">-</span><span style="color: #EEFFFF">y</span></div><div class='line'><span style="color: #EEFFFF">  C</span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF">np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">square</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">C</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  J</span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF">np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">sum</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">C</span><span style="color: #89DDFF">)/(</span><span style="color: #F78C6C">2</span><span style="color: #89DDFF">*</span><span style="color: #EEFFFF">m</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">return</span><span style="color: #EEFFFF"> J</span></div></code></div></pre>`,Hs,Os,qa=`<pre class="shiki material-default" style="background-color: #263238; color: #EEFFFF" python="true"><div class="language-id">python</div><div class='code-container'><code><div class='line'><span style="color: #546E7A"># Implementation of Gradient Descent Algorithm</span></div><div class='line'><span style="color: #C792EA">def</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">gradient_descent</span><span style="color: #89DDFF">(</span><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">y</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">theta</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF">alpha</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> num_iters</span><span style="color: #89DDFF">):</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #546E7A">  Performs the gradient descent for the Data given no of iterations</span></div><div class='line'></div><div class='line'><span style="color: #546E7A">  Arguments:</span></div><div class='line'><span style="color: #546E7A">  X: Input array of data (for uni-variate linear reg : dim = (m,2))</span></div><div class='line'><span style="color: #546E7A">  y: labels</span></div><div class='line'><span style="color: #546E7A">  theta: parameters matrix (for 2 parameters : dim = (2,1))</span></div><div class='line'><span style="color: #546E7A">  Note: Dimensions of H : (m,1), Dimensions of y : (m,1) (Both should be equal)</span></div><div class='line'><span style="color: #546E7A">  Returns:</span></div><div class='line'><span style="color: #546E7A">  Theta values after the minimization process of loss function</span></div><div class='line'><span style="color: #546E7A">  </span><span style="color: #89DDFF">"""</span></div><div class='line'><span style="color: #EEFFFF">  J_history </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">zeros</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">num_iters</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  m </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">len</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">  </span><span style="color: #89DDFF">for</span><span style="color: #EEFFFF"> iters </span><span style="color: #89DDFF">in</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">range</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">num_iters</span><span style="color: #89DDFF">-</span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">):</span></div><div class='line'><span style="color: #EEFFFF">    H </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">matmul</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF">theta</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    J </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">square</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">H</span><span style="color: #89DDFF">-</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    K </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">(</span><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">.</span><span style="color: #F07178">T</span><span style="color: #89DDFF">)</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">*</span><span style="color: #EEFFFF"> J</span></div><div class='line'><span style="color: #EEFFFF">    K </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> K</span><span style="color: #89DDFF">/</span><span style="color: #EEFFFF">m</span></div><div class='line'><span style="color: #EEFFFF">    </span><span style="color: #546E7A"># Theta update step(parameter update step)</span></div><div class='line'></div><div class='line'><span style="color: #EEFFFF">    theta </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> theta </span><span style="color: #89DDFF">-</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">((</span><span style="color: #EEFFFF">alpha</span><span style="color: #89DDFF">)*</span><span style="color: #EEFFFF">K</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    J_history</span><span style="color: #89DDFF">[</span><span style="color: #EEFFFF">iters</span><span style="color: #89DDFF">]</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> </span><span style="color: #82AAFF">compute_cost</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> y</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> theta</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">    </span><span style="color: #89DDFF">return</span><span style="color: #EEFFFF"> </span><span style="color: #89DDFF">[</span><span style="color: #EEFFFF">theta</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> J_history</span><span style="color: #89DDFF">]</span></div><div class='line'></div><div class='line'></div></code></div></pre>`,Bs,$s,Ja=`<pre class="shiki material-default" style="background-color: #263238; color: #EEFFFF" python="true"><div class="language-id">python</div><div class='code-container'><code><div class='line'><span style="color: #546E7A"># An example code snippet illustrating the linear regression </span></div><div class='line'><span style="color: #546E7A"># Loading the dataset and preparing the data for the model training</span></div><div class='line'><span style="color: #89DDFF">import</span><span style="color: #EEFFFF"> pandas </span><span style="color: #89DDFF">as</span><span style="color: #EEFFFF"> pd</span></div><div class='line'><span style="color: #EEFFFF">df </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> pd</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">read_csv</span><span style="color: #89DDFF">(</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">/content/linear_reg.csv</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">names</span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">[</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">X</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">,</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">y</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">])</span></div><div class='line'><span style="color: #EEFFFF">X </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> df</span><span style="color: #89DDFF">[</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">X</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">].</span><span style="color: #82AAFF">to_numpy</span><span style="color: #89DDFF">()</span></div><div class='line'><span style="color: #EEFFFF">y </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> df</span><span style="color: #89DDFF">[</span><span style="color: #89DDFF">"</span><span style="color: #C3E88D">y</span><span style="color: #89DDFF">"</span><span style="color: #89DDFF">].</span><span style="color: #82AAFF">to_numpy</span><span style="color: #89DDFF">()</span></div><div class='line'><span style="color: #EEFFFF">theta  </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">array</span><span style="color: #89DDFF">([</span><span style="color: #F78C6C">1</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">2</span><span style="color: #89DDFF">])</span></div><div class='line'><span style="color: #EEFFFF">X </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">expand_dims</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">X</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">axis</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">y </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">expand_dims</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">y</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">axis</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">theta </span><span style="color: #89DDFF">=</span><span style="color: #EEFFFF"> np</span><span style="color: #89DDFF">.</span><span style="color: #82AAFF">expand_dims</span><span style="color: #89DDFF">(</span><span style="color: #82AAFF">theta</span><span style="color: #89DDFF">,</span><span style="color: #82AAFF"> </span><span style="color: #EEFFFF">axis</span><span style="color: #82AAFF"> </span><span style="color: #89DDFF">=</span><span style="color: #82AAFF"> </span><span style="color: #F78C6C">1</span><span style="color: #89DDFF">)</span></div><div class='line'><span style="color: #EEFFFF">X</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> y</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span><span style="color: #89DDFF">,</span><span style="color: #EEFFFF"> theta</span><span style="color: #89DDFF">.</span><span style="color: #F07178">shape</span></div></code></div></pre>`,qs;return{c(){d=a("h1"),u=a("a"),b=t("Machine Learning Course Notes - AndrewNg(with code implementations of Algorithms)"),L=F(),y=a("blockquote"),m=a("p"),O=t("My entire Machine learning course notes along with code implementations for all algorithms. The notes are based on the course taught by AndrewNg offered by stanford on Coursera."),Js=F(),S=a("h2"),B=a("a"),ye=t("Introduction to Machine learning:"),Ks=F(),v=a("ul"),ds=a("li"),De=t("Types of ML problems"),fe=F(),$=a("li"),ue=t("Types of ML algorithms:"),h=a("ul"),ys=a("li"),me=t("Supervised learning"),Ee=F(),Ds=a("li"),he=t("Unsupervised learning"),ve=F(),fs=a("li"),ge=t("semi supervised learning"),Ae=F(),us=a("li"),_e=t("Reinforcement learning"),be=F(),ms=a("li"),we=t("Singular Value Decomposition method"),Ws=F(),N=a("h3"),q=a("a"),Le=t("Definition of Machine Learning:"),Zs=F(),J=a("p"),Te=t("Many attempts were made to define what is machine learning. Some of the prominent definitions are:"),zs=F(),T=a("ul"),K=a("li"),Es=a("strong"),Ce=t("Arthur Samuel(1959)"),Ie=t(" : Field of study that gives computers the ability to learn without being explicitly programmed."),xe=F(),g=a("li"),hs=a("strong"),Re=t("Tom Mitchell(1998)"),Me=t(":"),Se=a("br"),Ne=t(`
A well-posed learning problem is defined as:`),ke=a("br"),Ge=t(`
A computer program is said to learn from experience “E” with respect to some task “T” and some performance measure “P”, if its performance on T as measured by P improves with E.`),Vs=F(),W=a("p"),Ue=t("Ex:  An email program detecting spam mails. In this example:"),js=F(),A=a("ul"),Z=a("li"),vs=a("strong"),Xe=t("Task “T”:"),Pe=t(" classifying emails as spam or not"),He=F(),z=a("li"),gs=a("strong"),Oe=t("Experience “E”:"),Be=t(" watching you label email as spam or not spam"),$e=F(),V=a("li"),As=a("strong"),qe=t("Performance “P”:"),Je=t(" Fraction of emails correctly classified."),Qs=F(),k=a("h3"),j=a("a"),Ke=t("Types of ML Algorithms(based on learning methods):"),Ys=F(),E=a("ul"),Q=a("li"),_s=a("strong"),We=t("Supervised Learning:"),Ze=t(" We give the dataset which contains input data with the labelled ground truths so that the model can learn from it and when trained can produce results which are more close to the actual labels."),ze=F(),Y=a("li"),bs=a("strong"),Ve=t("Unsupervised Learning:"),je=t("   Allows us to approach problems with little or no idea what our results would look like. These learning algorithms are used to identify the patterns in dataset that has datapoints that are neither classified nor labelled."),Qe=F(),ss=a("li"),ws=a("strong"),Ye=t("Semi-supervised learning:"),sl=t("  is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). It is a special instance of weak supervision."),el=F(),es=a("li"),Ls=a("strong"),ll=t("Reinforcement learning:"),al=t(" Reinforcement learning is a machine learning training method based on rewarding desired behaviors and/or punishing undesired ones. In general, a reinforcement learning agent is able to perceive and interpret its environment, take actions and learn through trial and error."),se=F(),G=a("h3"),ls=a("a"),nl=t("Types of problems in supervised learning:"),ee=F(),C=a("ul"),as=a("li"),Ts=a("strong"),ol=t("Regression problems:"),tl=t(" These are problems where our predictions have continous value attribute.(for example: Housing price prediction given different factors as input in the dataset, here house prices are continuous value numbers)"),rl=F(),ns=a("li"),Cs=a("strong"),il=t("Classification problems"),pl=t(": These problems have predictions that are discrete valued (for example: output is there 0(or)1 for binary classification)"),le=F(),U=a("h3"),os=a("a"),Fl=t("Types of problems in Unsupervised learning:"),ae=F(),I=a("p"),cl=t("Given, a dataset the unsupervised learning algorithms will try to find some structure of pattern in the data. It decides that data lives in separate clusters. An example of this is "),Is=a("strong"),dl=t("“Clustering Algorithm”"),yl=t("."),ne=F(),ts=a("p"),Dl=t("Examples:"),oe=F(),x=a("ul"),xs=a("li"),fl=t("Like Newstories in google news are arranged in a cohesive way"),ul=F(),Rs=a("li"),ml=t("Genome identification and clustering the people based on genome."),te=F(),X=a("h2"),rs=a("a"),El=t("Regression problems (Linear Regression):"),re=F(),D=a("ul"),Ms=a("li"),hl=t("Weights and Bias units"),vl=F(),Ss=a("li"),gl=t("Contour plots"),Al=F(),Ns=a("li"),_l=t("Key Idea"),bl=F(),is=a("li"),wl=t("Gradient Descent Algorithm"),w=a("ul"),ks=a("li"),Ll=t("For linear regression"),Tl=F(),Gs=a("li"),Cl=t("Batch Gradient Descent"),Il=F(),Us=a("li"),xl=t("Gradient Descent for Multi variable regression"),Rl=F(),Xs=a("li"),Ml=t("Cost Function and Loss function"),ie=F(),Ps=new Jl(!1),Hs=F(),Os=new Jl(!1),Bs=F(),$s=new Jl(!1),qs=Oa(),this.h()},l(s){d=n(s,"H1",{id:!0});var i=o(d);u=n(i,"A",{href:!0});var Zl=o(u);b=r(Zl,"Machine Learning Course Notes - AndrewNg(with code implementations of Algorithms)"),Zl.forEach(l),i.forEach(l),L=c(s),y=n(s,"BLOCKQUOTE",{});var zl=o(y);m=n(zl,"P",{});var Vl=o(m);O=r(Vl,"My entire Machine learning course notes along with code implementations for all algorithms. The notes are based on the course taught by AndrewNg offered by stanford on Coursera."),Vl.forEach(l),zl.forEach(l),Js=c(s),S=n(s,"H2",{id:!0});var jl=o(S);B=n(jl,"A",{href:!0});var Ql=o(B);ye=r(Ql,"Introduction to Machine learning:"),Ql.forEach(l),jl.forEach(l),Ks=c(s),v=n(s,"UL",{});var ps=o(v);ds=n(ps,"LI",{});var Yl=o(ds);De=r(Yl,"Types of ML problems"),Yl.forEach(l),fe=c(ps),$=n(ps,"LI",{});var Sl=o($);ue=r(Sl,"Types of ML algorithms:"),h=n(Sl,"UL",{});var R=o(h);ys=n(R,"LI",{});var sa=o(ys);me=r(sa,"Supervised learning"),sa.forEach(l),Ee=c(R),Ds=n(R,"LI",{});var ea=o(Ds);he=r(ea,"Unsupervised learning"),ea.forEach(l),ve=c(R),fs=n(R,"LI",{});var la=o(fs);ge=r(la,"semi supervised learning"),la.forEach(l),Ae=c(R),us=n(R,"LI",{});var aa=o(us);_e=r(aa,"Reinforcement learning"),aa.forEach(l),R.forEach(l),Sl.forEach(l),be=c(ps),ms=n(ps,"LI",{});var na=o(ms);we=r(na,"Singular Value Decomposition method"),na.forEach(l),ps.forEach(l),Ws=c(s),N=n(s,"H3",{id:!0});var oa=o(N);q=n(oa,"A",{href:!0});var ta=o(q);Le=r(ta,"Definition of Machine Learning:"),ta.forEach(l),oa.forEach(l),Zs=c(s),J=n(s,"P",{});var ra=o(J);Te=r(ra,"Many attempts were made to define what is machine learning. Some of the prominent definitions are:"),ra.forEach(l),zs=c(s),T=n(s,"UL",{});var pe=o(T);K=n(pe,"LI",{});var Nl=o(K);Es=n(Nl,"STRONG",{});var ia=o(Es);Ce=r(ia,"Arthur Samuel(1959)"),ia.forEach(l),Ie=r(Nl," : Field of study that gives computers the ability to learn without being explicitly programmed."),Nl.forEach(l),xe=c(pe),g=n(pe,"LI",{});var P=o(g);hs=n(P,"STRONG",{});var pa=o(hs);Re=r(pa,"Tom Mitchell(1998)"),pa.forEach(l),Me=r(P,":"),Se=n(P,"BR",{}),Ne=r(P,`
A well-posed learning problem is defined as:`),ke=n(P,"BR",{}),Ge=r(P,`
A computer program is said to learn from experience “E” with respect to some task “T” and some performance measure “P”, if its performance on T as measured by P improves with E.`),P.forEach(l),pe.forEach(l),Vs=c(s),W=n(s,"P",{});var Fa=o(W);Ue=r(Fa,"Ex:  An email program detecting spam mails. In this example:"),Fa.forEach(l),js=c(s),A=n(s,"UL",{});var Fs=o(A);Z=n(Fs,"LI",{});var kl=o(Z);vs=n(kl,"STRONG",{});var ca=o(vs);Xe=r(ca,"Task “T”:"),ca.forEach(l),Pe=r(kl," classifying emails as spam or not"),kl.forEach(l),He=c(Fs),z=n(Fs,"LI",{});var Gl=o(z);gs=n(Gl,"STRONG",{});var da=o(gs);Oe=r(da,"Experience “E”:"),da.forEach(l),Be=r(Gl," watching you label email as spam or not spam"),Gl.forEach(l),$e=c(Fs),V=n(Fs,"LI",{});var Ul=o(V);As=n(Ul,"STRONG",{});var ya=o(As);qe=r(ya,"Performance “P”:"),ya.forEach(l),Je=r(Ul," Fraction of emails correctly classified."),Ul.forEach(l),Fs.forEach(l),Qs=c(s),k=n(s,"H3",{id:!0});var Da=o(k);j=n(Da,"A",{href:!0});var fa=o(j);Ke=r(fa,"Types of ML Algorithms(based on learning methods):"),fa.forEach(l),Da.forEach(l),Ys=c(s),E=n(s,"UL",{});var M=o(E);Q=n(M,"LI",{});var Xl=o(Q);_s=n(Xl,"STRONG",{});var ua=o(_s);We=r(ua,"Supervised Learning:"),ua.forEach(l),Ze=r(Xl," We give the dataset which contains input data with the labelled ground truths so that the model can learn from it and when trained can produce results which are more close to the actual labels."),Xl.forEach(l),ze=c(M),Y=n(M,"LI",{});var Pl=o(Y);bs=n(Pl,"STRONG",{});var ma=o(bs);Ve=r(ma,"Unsupervised Learning:"),ma.forEach(l),je=r(Pl,"   Allows us to approach problems with little or no idea what our results would look like. These learning algorithms are used to identify the patterns in dataset that has datapoints that are neither classified nor labelled."),Pl.forEach(l),Qe=c(M),ss=n(M,"LI",{});var Hl=o(ss);ws=n(Hl,"STRONG",{});var Ea=o(ws);Ye=r(Ea,"Semi-supervised learning:"),Ea.forEach(l),sl=r(Hl,"  is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). It is a special instance of weak supervision."),Hl.forEach(l),el=c(M),es=n(M,"LI",{});var Ol=o(es);Ls=n(Ol,"STRONG",{});var ha=o(Ls);ll=r(ha,"Reinforcement learning:"),ha.forEach(l),al=r(Ol," Reinforcement learning is a machine learning training method based on rewarding desired behaviors and/or punishing undesired ones. In general, a reinforcement learning agent is able to perceive and interpret its environment, take actions and learn through trial and error."),Ol.forEach(l),M.forEach(l),se=c(s),G=n(s,"H3",{id:!0});var va=o(G);ls=n(va,"A",{href:!0});var ga=o(ls);nl=r(ga,"Types of problems in supervised learning:"),ga.forEach(l),va.forEach(l),ee=c(s),C=n(s,"UL",{});var Fe=o(C);as=n(Fe,"LI",{});var Bl=o(as);Ts=n(Bl,"STRONG",{});var Aa=o(Ts);ol=r(Aa,"Regression problems:"),Aa.forEach(l),tl=r(Bl," These are problems where our predictions have continous value attribute.(for example: Housing price prediction given different factors as input in the dataset, here house prices are continuous value numbers)"),Bl.forEach(l),rl=c(Fe),ns=n(Fe,"LI",{});var $l=o(ns);Cs=n($l,"STRONG",{});var _a=o(Cs);il=r(_a,"Classification problems"),_a.forEach(l),pl=r($l,": These problems have predictions that are discrete valued (for example: output is there 0(or)1 for binary classification)"),$l.forEach(l),Fe.forEach(l),le=c(s),U=n(s,"H3",{id:!0});var ba=o(U);os=n(ba,"A",{href:!0});var wa=o(os);Fl=r(wa,"Types of problems in Unsupervised learning:"),wa.forEach(l),ba.forEach(l),ae=c(s),I=n(s,"P",{});var ce=o(I);cl=r(ce,"Given, a dataset the unsupervised learning algorithms will try to find some structure of pattern in the data. It decides that data lives in separate clusters. An example of this is "),Is=n(ce,"STRONG",{});var La=o(Is);dl=r(La,"“Clustering Algorithm”"),La.forEach(l),yl=r(ce,"."),ce.forEach(l),ne=c(s),ts=n(s,"P",{});var Ta=o(ts);Dl=r(Ta,"Examples:"),Ta.forEach(l),oe=c(s),x=n(s,"UL",{});var de=o(x);xs=n(de,"LI",{});var Ca=o(xs);fl=r(Ca,"Like Newstories in google news are arranged in a cohesive way"),Ca.forEach(l),ul=c(de),Rs=n(de,"LI",{});var Ia=o(Rs);ml=r(Ia,"Genome identification and clustering the people based on genome."),Ia.forEach(l),de.forEach(l),te=c(s),X=n(s,"H2",{id:!0});var xa=o(X);rs=n(xa,"A",{href:!0});var Ra=o(rs);El=r(Ra,"Regression problems (Linear Regression):"),Ra.forEach(l),xa.forEach(l),re=c(s),D=n(s,"UL",{});var _=o(D);Ms=n(_,"LI",{});var Ma=o(Ms);hl=r(Ma,"Weights and Bias units"),Ma.forEach(l),vl=c(_),Ss=n(_,"LI",{});var Sa=o(Ss);gl=r(Sa,"Contour plots"),Sa.forEach(l),Al=c(_),Ns=n(_,"LI",{});var Na=o(Ns);_l=r(Na,"Key Idea"),Na.forEach(l),bl=c(_),is=n(_,"LI",{});var ql=o(is);wl=r(ql,"Gradient Descent Algorithm"),w=n(ql,"UL",{});var cs=o(w);ks=n(cs,"LI",{});var ka=o(ks);Ll=r(ka,"For linear regression"),ka.forEach(l),Tl=c(cs),Gs=n(cs,"LI",{});var Ga=o(Gs);Cl=r(Ga,"Batch Gradient Descent"),Ga.forEach(l),Il=c(cs),Us=n(cs,"LI",{});var Ua=o(Us);xl=r(Ua,"Gradient Descent for Multi variable regression"),Ua.forEach(l),cs.forEach(l),ql.forEach(l),Rl=c(_),Xs=n(_,"LI",{});var Xa=o(Xs);Ml=r(Xa,"Cost Function and Loss function"),Xa.forEach(l),_.forEach(l),ie=c(s),Ps=Kl(s,!1),Hs=c(s),Os=Kl(s,!1),Bs=c(s),$s=Kl(s,!1),qs=Oa(),this.h()},h(){f(u,"href","#machine-learning-course-notes---andrewngwith-code-implementations-of-algorithms"),f(d,"id","machine-learning-course-notes---andrewngwith-code-implementations-of-algorithms"),f(B,"href","#introduction-to-machine-learning"),f(S,"id","introduction-to-machine-learning"),f(q,"href","#definition-of-machine-learning"),f(N,"id","definition-of-machine-learning"),f(j,"href","#types-of-ml-algorithmsbased-on-learning-methods"),f(k,"id","types-of-ml-algorithmsbased-on-learning-methods"),f(ls,"href","#types-of-problems-in-supervised-learning"),f(G,"id","types-of-problems-in-supervised-learning"),f(os,"href","#types-of-problems-in-unsupervised-learning"),f(U,"id","types-of-problems-in-unsupervised-learning"),f(rs,"href","#regression-problems-linear-regression"),f(X,"id","regression-problems-linear-regression"),Ps.a=Hs,Os.a=Bs,$s.a=qs},m(s,i){p(s,d,i),e(d,u),e(u,b),p(s,L,i),p(s,y,i),e(y,m),e(m,O),p(s,Js,i),p(s,S,i),e(S,B),e(B,ye),p(s,Ks,i),p(s,v,i),e(v,ds),e(ds,De),e(v,fe),e(v,$),e($,ue),e($,h),e(h,ys),e(ys,me),e(h,Ee),e(h,Ds),e(Ds,he),e(h,ve),e(h,fs),e(fs,ge),e(h,Ae),e(h,us),e(us,_e),e(v,be),e(v,ms),e(ms,we),p(s,Ws,i),p(s,N,i),e(N,q),e(q,Le),p(s,Zs,i),p(s,J,i),e(J,Te),p(s,zs,i),p(s,T,i),e(T,K),e(K,Es),e(Es,Ce),e(K,Ie),e(T,xe),e(T,g),e(g,hs),e(hs,Re),e(g,Me),e(g,Se),e(g,Ne),e(g,ke),e(g,Ge),p(s,Vs,i),p(s,W,i),e(W,Ue),p(s,js,i),p(s,A,i),e(A,Z),e(Z,vs),e(vs,Xe),e(Z,Pe),e(A,He),e(A,z),e(z,gs),e(gs,Oe),e(z,Be),e(A,$e),e(A,V),e(V,As),e(As,qe),e(V,Je),p(s,Qs,i),p(s,k,i),e(k,j),e(j,Ke),p(s,Ys,i),p(s,E,i),e(E,Q),e(Q,_s),e(_s,We),e(Q,Ze),e(E,ze),e(E,Y),e(Y,bs),e(bs,Ve),e(Y,je),e(E,Qe),e(E,ss),e(ss,ws),e(ws,Ye),e(ss,sl),e(E,el),e(E,es),e(es,Ls),e(Ls,ll),e(es,al),p(s,se,i),p(s,G,i),e(G,ls),e(ls,nl),p(s,ee,i),p(s,C,i),e(C,as),e(as,Ts),e(Ts,ol),e(as,tl),e(C,rl),e(C,ns),e(ns,Cs),e(Cs,il),e(ns,pl),p(s,le,i),p(s,U,i),e(U,os),e(os,Fl),p(s,ae,i),p(s,I,i),e(I,cl),e(I,Is),e(Is,dl),e(I,yl),p(s,ne,i),p(s,ts,i),e(ts,Dl),p(s,oe,i),p(s,x,i),e(x,xs),e(xs,fl),e(x,ul),e(x,Rs),e(Rs,ml),p(s,te,i),p(s,X,i),e(X,rs),e(rs,El),p(s,re,i),p(s,D,i),e(D,Ms),e(Ms,hl),e(D,vl),e(D,Ss),e(Ss,gl),e(D,Al),e(D,Ns),e(Ns,_l),e(D,bl),e(D,is),e(is,wl),e(is,w),e(w,ks),e(ks,Ll),e(w,Tl),e(w,Gs),e(Gs,Cl),e(w,Il),e(w,Us),e(Us,xl),e(D,Rl),e(D,Xs),e(Xs,Ml),p(s,ie,i),Ps.m($a,s,i),p(s,Hs,i),Os.m(qa,s,i),p(s,Bs,i),$s.m(Ja,s,i),p(s,qs,i)},p:ln,d(s){s&&l(d),s&&l(L),s&&l(y),s&&l(Js),s&&l(S),s&&l(Ks),s&&l(v),s&&l(Ws),s&&l(N),s&&l(Zs),s&&l(J),s&&l(zs),s&&l(T),s&&l(Vs),s&&l(W),s&&l(js),s&&l(A),s&&l(Qs),s&&l(k),s&&l(Ys),s&&l(E),s&&l(se),s&&l(G),s&&l(ee),s&&l(C),s&&l(le),s&&l(U),s&&l(ae),s&&l(I),s&&l(ne),s&&l(ts),s&&l(oe),s&&l(x),s&&l(te),s&&l(X),s&&l(re),s&&l(D),s&&l(ie),s&&Ps.d(),s&&l(Hs),s&&Os.d(),s&&l(Bs),s&&l(qs),s&&$s.d()}}}function on(H){let d,u;const b=[H[0],Ba];let L={$$slots:{default:[nn]},$$scope:{ctx:H}};for(let y=0;y<b.length;y+=1)L=Wl(L,b[y]);return d=new an({props:L}),{c(){za(d.$$.fragment)},l(y){Va(d.$$.fragment,y)},m(y,m){ja(d,y,m),u=!0},p(y,[m]){const O=m&1?Qa(b,[m&1&&Pa(y[0]),m&0&&Pa(Ba)]):{};m&2&&(O.$$scope={dirty:m,ctx:y}),d.$set(O)},i(y){u||(Ya(d.$$.fragment,y),u=!0)},o(y){sn(d.$$.fragment,y),u=!1},d(y){en(d,y)}}}const Ba={title:"Machine Learning Cousre Notes(Andrew Ng Course)",image:"/hello-world/urara.webp",created:"2021-11-01T00:00:00.000Z",updated:"2021-12-12T00:00:00.000Z",published:"2021-11-04T00:00:00.000Z",tags:["Machine Learning","AndrewNg"],flags:["unlisted"],slug:"/machine-learning-notes/+page.md",path:"/machine-learning-notes",toc:[{depth:1,title:"Machine Learning Course Notes - AndrewNg(with code implementations of Algorithms)",slug:"machine-learning-course-notes---andrewngwith-code-implementations-of-algorithms"},{depth:2,title:"Introduction to Machine learning:",slug:"introduction-to-machine-learning"},{depth:3,title:"Definition of Machine Learning:",slug:"definition-of-machine-learning"},{depth:3,title:"Types of ML Algorithms(based on learning methods):",slug:"types-of-ml-algorithmsbased-on-learning-methods"},{depth:3,title:"Types of problems in supervised learning:",slug:"types-of-problems-in-supervised-learning"},{depth:3,title:"Types of problems in Unsupervised learning:",slug:"types-of-problems-in-unsupervised-learning"},{depth:2,title:"Regression problems (Linear Regression):",slug:"regression-problems-linear-regression"}]};function tn(H,d,u){return H.$$set=b=>{u(0,d=Wl(Wl({},d),Ha(b)))},d=Ha(d),[d]}class Fn extends Ka{constructor(d){super(),Wa(this,d,tn,on,Za,{})}}export{Fn as default,Ba as metadata};
